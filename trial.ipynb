{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyMuPDFLoader, DirectoryLoader,PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "# from langchain.retrievers import PineconeRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(data_extracted):\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(data_extracted)\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\medical-book.pdf', 'page': 50, 'page_label': '51'}, page_content='Acupressure points to relieve hay fever, sore throat, and\\nheartburn. (Illustration by Electronic Illustrators Group.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 37')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def download_embeddings():\n",
    "    # Define the path where the embeddings should be saved\n",
    "    cache_dir = os.path.join(os.getcwd(), \"models\")\n",
    "    \n",
    "    # Initialize embeddings with the specified cache directory\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        cache_folder=cache_dir\n",
    "    )\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jatin\\AppData\\Local\\Temp\\ipykernel_20976\\4148669211.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\conda-envs\\openaidemo\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder='d:\\\\Tutorial\\\\GenAI\\\\Projects\\\\Medical-Chatbot\\\\models', model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"hello world\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This will load the environment variables from the .env file\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV= os.getenv('PINECONE_API_ENV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_2oVXis_TBuupQJDi3qHCGHL5BQifhBAMfCiWfU69WtbNnQdQfi21KSMeCUqMsrWZuKVLXu\n",
      "aped-4627-b74a\n"
     ]
    }
   ],
   "source": [
    "print(PINECONE_API_KEY)\n",
    "print(PINECONE_API_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY,environment=PINECONE_API_ENV)\n",
    "\n",
    "# Connect to your existing index\n",
    "index_name = \"medical-chatbot\"\n",
    "index = pc.Index(index_name)  # Use the .index() method to retrieve the existing index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x2ba2746f670>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a HuggingFaceEmbeddings instance called 'embeddings'\n",
    "upsert_data = [(str(i), embeddings.embed_query(text_chunks[i].page_content),{\"text\": text_chunks[i].page_content}) for i in range(len(text_chunks))]\n",
    "\n",
    "# Perform the upsert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', [0.021459683775901794, -0.008097134530544281, -0.026178136467933655, 0.016104133799672127, -0.03194974735379219, 0.00957584474235773, 0.00321900169365108, 0.19288143515586853, -0.032423410564661026, -0.041329674422740936, 0.005839129909873009, 0.08297932147979736, 0.04542427137494087, 0.02660774625837803, -0.11355927586555481, 0.006353229284286499, -0.03204401955008507, -0.030400892719626427, -0.007295815274119377, -0.02290460467338562, -0.050757940858602524, 0.08314482122659683, 0.05323915556073189, 0.0234315637499094, -0.08658876270055771, 0.0478459969162941, -0.05883761867880821, -0.05568983778357506, -0.001716391183435917, -0.01642111875116825, -0.0034194032195955515, 0.09850358217954636, 0.055149514228105545, -0.013974909670650959, -0.00471839401870966, -0.04058890789747238, 0.018936995416879654, 0.028466319665312767, -0.04568350687623024, 0.10384681075811386, 0.0267010610550642, -0.06810127198696136, -0.0347861684858799, -0.0038320529274642467, 0.06335132569074631, 0.051609452813863754, -0.04729421064257622, 0.021285539492964745, 0.03772132471203804, 0.10608897358179092, -0.08572103083133698, -0.052595291286706924, -0.05198218300938606, 0.09211566299200058, 0.055632974952459335, 0.007448562420904636, -0.09788715839385986, -0.04699094966053963, -0.13488207757472992, -0.03262481465935707, -0.003083650255575776, 0.02635146491229534, -0.02720060758292675, 0.05815045163035393, -0.051880430430173874, -0.013277419842779636, 0.08011142909526825, -0.012560393661260605, 0.045984286814928055, -0.018374836072325706, -0.01668369583785534, -0.01709207333624363, 0.06107904016971588, 0.05939541012048721, -0.037678156048059464, -0.05707627534866333, 0.012811795808374882, -0.07517246156930923, -0.031928423792123795, -0.09606542438268661, 0.010719534009695053, 0.016127513721585274, 0.026679551228880882, -0.0020103224087506533, -0.06675642728805542, -0.02420419454574585, 0.022528398782014847, -0.006961358245462179, -0.026830393821001053, -0.04471903666853905, 0.08031858503818512, -0.07292792201042175, 0.030992930755019188, -0.013487090356647968, 0.04210494086146355, 0.04626428335905075, -0.01716800034046173, -0.026450691744685173, -0.03948129713535309, 0.062847800552845, -0.007649750914424658, -0.11860097944736481, -0.009043809957802296, 0.022964145988225937, 0.018267329782247543, -0.052779801189899445, 0.005642964504659176, -0.07451102882623672, 0.02742786519229412, -0.013205631636083126, 0.015458152629435062, 0.05901069939136505, -0.009956898167729378, -0.0304860882461071, 0.034340452402830124, 0.04395383968949318, 0.09472277760505676, 0.045105431228876114, 0.07995718717575073, 0.03887902572751045, 0.011221824213862419, -0.10234421491622925, -0.03469269350171089, -0.08858337998390198, 0.02097894623875618, -0.011448261328041553, -0.03617043420672417, -4.023393167234245e-33, 0.0064255367033183575, -0.01876680552959442, 0.048002906143665314, 0.07439754903316498, 0.042539142072200775, 0.01456448808312416, 0.003543389495462179, -0.09640392661094666, 0.058844756335020065, -0.09534236788749695, -0.0767323300242424, 0.0666060820221901, 0.032112281769514084, 0.018843842670321465, -0.06468842178583145, 0.017497021704912186, -0.0795716941356659, 0.1213393285870552, 0.039357565343379974, -0.008798548951745033, 0.006126670632511377, 0.0393332913517952, -0.05873771011829376, 0.00460603553801775, -0.042945101857185364, 0.0996798500418663, 0.018893074244260788, -0.0541532076895237, 0.08771806955337524, -0.013312081806361675, -0.010632507503032684, 0.0018019487615674734, -0.011010682210326195, -0.03378324210643768, -0.028600018471479416, 0.07927095144987106, -0.0818483829498291, -0.013551565818488598, 0.021024439483880997, -0.04593708738684654, 0.02904452756047249, 0.04909594729542732, 0.04702608659863472, -0.013700958341360092, 0.08744654059410095, -0.005767183844000101, -0.10580173879861832, 0.009210165590047836, 0.03405452147126198, -0.07740210741758347, 0.01803082786500454, 0.004661427810788155, 0.05032433196902275, -0.04486656188964844, 0.012895914725959301, 0.04080222547054291, -0.0515686459839344, 0.044195082038640976, -0.015911033377051353, 0.06225588917732239, 0.0747542679309845, 0.07200463116168976, 0.03641585260629654, 0.009203269146382809, 0.0305698961019516, -0.015757327899336815, -0.11254432052373886, -0.08758116513490677, -0.052214059978723526, -0.029345374554395676, -0.16705577075481415, 0.03117232583463192, 0.039679620414972305, 0.01700366474688053, -0.02827589027583599, 0.0006158119649626315, 0.024489616975188255, -0.019497765228152275, -0.09599126875400543, -0.10247129201889038, -0.0705987960100174, -0.03730887174606323, 0.03767046332359314, 0.15446136891841888, -0.016338486224412918, -0.024643851444125175, 0.03316575661301613, -0.012394520454108715, -0.05980714410543442, -0.02522873319685459, -0.02730013243854046, 0.044666171073913574, -0.03330647572875023, 0.016206441447138786, -0.04089706018567085, 9.565235730959113e-35, 0.008231224492192268, -0.061384569853544235, 0.028051791712641716, 0.014862674288451672, 0.05971147492527962, 0.08927346020936966, -0.044058941304683685, 0.06923266500234604, 0.01685851253569126, 0.0097886947914958, 0.09168361872434616, 0.02615397609770298, -0.0071872263215482235, -0.03209425136446953, -0.032731711864471436, 0.023340025916695595, -0.004052429459989071, -0.015931114554405212, -0.034376055002212524, 0.056755077093839645, -0.07175585627555847, 0.05265694856643677, -0.04533327743411064, -0.024194344878196716, 0.0412287712097168, 0.026490673422813416, 0.0599435493350029, -0.03250664100050926, -0.05399826541543007, -0.046276941895484924, -0.0012530068634077907, -0.03994370996952057, -0.059709545224905014, -0.057104453444480896, -0.03567034751176834, 0.009510153904557228, -0.0036783828400075436, -0.060125548392534256, -0.03662633150815964, -0.059966377913951874, 0.0676819458603859, -0.016377903521060944, 0.03961901739239693, 0.01755102165043354, 0.006852088961750269, -0.03769998997449875, -0.02424413524568081, 0.012098364531993866, 0.02083233743906021, 0.016729505732655525, 0.06380270421504974, -0.025921769440174103, -0.01461968943476677, 0.03252044692635536, 0.018622485920786858, -0.01727209985256195, -0.0422995425760746, -0.12999972701072693, 0.027612850069999695, -0.011769800446927547, -0.033700715750455856, 0.018340356647968292, -0.09740448743104935, 0.0886337161064148, -0.010573777370154858, 0.02213156409561634, 0.0012856802204623818, 0.014248235151171684, -0.011681405827403069, 0.00810924731194973, -0.026780705899000168, 0.0277089886367321, -0.013411419466137886, -0.030273498967289925, 0.02317294105887413, -0.00795004889369011, -0.016029736027121544, -0.040323104709386826, -0.02822183631360531, -0.05502830073237419, 0.012381578795611858, -0.07676910609006882, 0.013830051757395267, 0.08974920213222504, -0.024001114070415497, -0.0053398497402668, 0.04341930150985718, 0.006656148005276918, -0.008272641338407993, -0.004966153297573328, -0.04764524847269058, -0.004063962493091822, -0.11115054786205292, 0.007015877868980169, 0.03894106298685074, -2.106925123257497e-08, 0.031274788081645966, 0.006839667446911335, 0.008706371299922466, 0.0008982219733297825, -0.04053528234362602, -0.039974335581064224, -0.05287687107920647, 0.09972617030143738, -0.05302278697490692, 0.0801522508263588, -0.07462772727012634, 0.10294725745916367, 0.03608419746160507, -0.021827999502420425, 0.011665827594697475, 0.05917627364397049, 0.014603628776967525, 0.050073444843292236, -0.046014707535505295, -0.04942888021469116, 0.032005153596401215, -0.025556696578860283, 0.05291933938860893, -0.06819111853837967, 0.03574283421039581, 0.04215051606297493, -0.007696500048041344, -0.05262790247797966, 0.024692116305232048, -0.0649089589715004, 0.012308765202760696, 0.04961670935153961, 0.023892737925052643, -0.05053735896945, 0.004350755363702774, -0.023776575922966003, 0.05649585649371147, -0.04181577265262604, -0.0010606002761051059, -0.02377719059586525, 0.011978236958384514, -0.039904601871967316, 0.010357736609876156, 0.03463945910334587, 0.04932782053947449, -0.05338601395487785, 0.08978116512298584, 0.0628877729177475, 0.0357416532933712, -0.040358059108257294, 0.021238356828689575, 0.035413455218076706, 0.15282942354679108, -0.03880957514047623, -0.09681108593940735, 0.06338956207036972, 0.040718112140893936, -0.030306603759527206, 0.005510667338967323, -0.03285100311040878, 0.003690088167786598, 0.0005134264938533306, 0.04615558311343193, 0.08530807495117188], {'text': 'The GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION'})\n"
     ]
    }
   ],
   "source": [
    "print(upsert_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexes': [{'deletion_protection': 'disabled',\n",
      "              'dimension': 384,\n",
      "              'host': 'medical-chatbot-bc4fyf5.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'medical-chatbot',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n",
      "Description of index: \n",
      " {'deletion_protection': 'disabled',\n",
      " 'dimension': 384,\n",
      " 'host': 'medical-chatbot-bc4fyf5.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'medical-chatbot',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "print(pc.list_indexes())\n",
    "description = pc.describe_index(\"medical-chatbot\")\n",
    "print(f\"Description of index: \\n {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  # or any number that suits your data size\n",
    "for i in range(0, len(upsert_data), batch_size):\n",
    "    batch = upsert_data[i:i + batch_size]\n",
    "    index.upsert(vectors=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are allergies?\"\n",
    "query_embedding = embeddings.embed_query(query)  # encoding query text into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform similarity search\n",
    "results = index.query(\n",
    "    vector=query_embedding,  # Query vector\n",
    "    top_k=3,  # Retrieve top 3 most similar documents\n",
    "    include_metadata=True  # Include metadata if available\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "# for match in results['matches']:\n",
    "#     print(f\"Score: {match['score']}, Text: {match['metadata']['text']}\")\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda-envs\\openaidemo\\lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Pinecone(\n",
    "    index=index,  # Pinecone index instance\n",
    "    embedding=embeddings.embed_query,  # Embedding function\n",
    "    text_key=\"text\"  # Key in metadata containing the document text\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\" \n",
    "Use the following peices of information to answer the user's question \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:{context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=prompt_template,input_variables=['context','question'])\n",
    "chain_type_kwargs = {\"prompt\":prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config={'max_new_tokens':512,\n",
    "                            'temperature':0.6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jatin\\AppData\\Local\\Temp\\ipykernel_20976\\2207261093.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Allergies are a reaction of the immune system where the body mistakenly identifies harmless substances as threats, triggering an inappropriate and exaggerated response. This can result in a range of symptoms including itchy eyes, runny nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, noses, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, and cong, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, stuffy nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, and cong nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, and stuffy nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, and cong noses, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, and cong nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, and cong nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose, nose\n"
     ]
    }
   ],
   "source": [
    "question = \"What are allergies?\"\n",
    "answer = qa_chain.run(question)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaidemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
